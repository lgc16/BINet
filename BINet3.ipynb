{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此程序对应BINet文章第四个例子，求解不同波数下的Helmholtz方程外问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "1.6.0+cu101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as v\n",
    "import scipy.special as scp\n",
    "import time\n",
    "\n",
    "is_gpu = torch.cuda.is_available()\n",
    "if is_gpu:\n",
    "    id = 2\n",
    "    torch.cuda.set_device(id)\n",
    "    \n",
    "#gpu_nums = torch.cuda.device_count()\n",
    "#gpu_index = torch.cuda.current_device()\n",
    "#print(is_gpu,gpu_nums,gpu_index)\n",
    "device = torch.device('cuda' if is_gpu else 'cpu')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计问题区域\n",
    "\n",
    "# k                波数，取值范围为[2,3.5]∪[4.5,6]\n",
    "# k_num            随机采样的k的个数\n",
    "# sample_num       边界上样本点数\n",
    "# theta, r, x0, x1 辅助确定边界点坐标\n",
    "# sample_x         边界样本点坐标\n",
    "# sample_u_r       准确解实部\n",
    "# sample_u_i       准确解虚部\n",
    "# rprime           边界参数化方程在样本点处切向量\n",
    "# int_n            样本点处的外法向量\n",
    "# sample_xk        构造网络的输入，即样本点坐标+k的值共同作为输入\n",
    "k_num = 70\n",
    "k = torch.cat((torch.rand(30)*1.5+2,torch.rand(40)*1.5+4.5),0)\n",
    " \n",
    "sample_num = 1000 \n",
    "\n",
    "theta = torch.linspace(2*np.pi/sample_num,2*np.pi,sample_num).reshape(-1,1)\n",
    "r = 9/20-1/9*torch.cos(5*theta)\n",
    "x0,x1 = torch.cos(theta),torch.sin(theta)\n",
    "sample_x = torch.cat((x0,x1),1)*r\n",
    "rprime = torch.cat((-x1*r+5/9*torch.sin(5*theta)*x0,x0*r+5/9*torch.sin(5*theta)*x1),1)\n",
    "int_n = rprime@torch.Tensor([[0,-1],[1,0]])\n",
    "int_n = int_n/((int_n*int_n).sum(axis=1).reshape(-1,1).sqrt())\n",
    "\n",
    "sample_xk = torch.zeros(sample_num*k_num,3)\n",
    "\n",
    "\n",
    "sample_u_r = torch.zeros(k_num,sample_num)\n",
    "sample_u_i = torch.zeros(k_num,sample_num)\n",
    "for l in range(k_num):\n",
    "    sample_u_r[l,:] = scp.hankel1(0,k[l]*torch.sqrt((sample_x[:,0])**2+sample_x[:,1]**2)).real\n",
    "    sample_u_i[l,:] = scp.hankel1(0,k[l]*torch.sqrt((sample_x[:,0])**2+sample_x[:,1]**2)).imag\n",
    "    sample_xk[l*sample_num:(l+1)*sample_num,0:2] = sample_x\n",
    "    sample_xk[l*sample_num:(l+1)*sample_num,2] = k[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置积分矩阵，对于每个k要构造相应的矩阵\n",
    "\n",
    "# G1_r    基本解的实部\n",
    "# G1_i    基本解的虚部\n",
    "# A1_r    积分矩阵的实部\n",
    "# A1_i    积分矩阵的虚部\n",
    "# KaparR2 Kapar奇异积分格式的权重\n",
    "\n",
    "r0 = torch.zeros(sample_num,sample_num)\n",
    "n1 = torch.zeros(sample_num,sample_num)\n",
    "c = torch.zeros(sample_num,sample_num)\n",
    "KaparR2 = torch.zeros(sample_num,1)\n",
    "KaparR2[0],KaparR2[1] = 1.825748064736159,-1.325748064736159\n",
    "for i in range(sample_num):\n",
    "    for j in range(sample_num):\n",
    "        d = sample_x[j,:]-sample_x[i,:]\n",
    "        r0[i,j] = d.norm()\n",
    "        n1[i,j] = (int_n[j,:]*d).sum()\n",
    "        c[i,j] = (1+KaparR2[abs(((i-j)+round(sample_num/2))%sample_num-round(sample_num/2)-1)])*((rprime[j,:]).norm())/sample_num*2*np.pi\n",
    "\n",
    "G2_r = torch.zeros(k_num,sample_num,sample_num)\n",
    "G2_i = torch.zeros(k_num,sample_num,sample_num)\n",
    "for l in range(k_num):\n",
    "    G2_r[l,:,:] = scp.hankel1(1,k[l]*r0).imag/4*n1/r0*k[l]\n",
    "    G2_i[l,:,:] = -scp.hankel1(1,k[l]*r0).real/4*n1/r0*k[l]\n",
    "\n",
    "\n",
    "A2_r = torch.zeros(k_num,sample_num,sample_num)\n",
    "A2_i = torch.zeros(k_num,sample_num,sample_num)\n",
    "for l in range(k_num):\n",
    "    for i in range(sample_num):\n",
    "        A2_r[l,i,:],A2_i[l,i,:] = -c[i,:]*G2_r[l,i,:],-c[i,:]*G2_i[l,i,:]\n",
    "        A2_r[l,i,i],A2_i[l,i,i] = -1/2,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构和损失函数\n",
    "\n",
    "# ResNet结构\n",
    "# m   神经元个数\n",
    "# out 输出维数\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,m,out):\n",
    "    super(Net, self).__init__()\n",
    "    self.input = nn.Linear(3,m)\n",
    "    self.block1=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block2=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block3=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block4=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block5=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block6=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block7=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block8=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.out = nn.Linear(m,out)\n",
    "  def forward(self, x):\n",
    "      x = self.input(x)\n",
    "      x = self.block1(x) + x\n",
    "      x = self.block2(x) + x\n",
    "      x = self.block3(x) + x\n",
    "      x = self.block4(x) + x\n",
    "      x = self.block5(x) + x\n",
    "      x = self.block6(x) + x\n",
    "      x = self.block7(x) + x\n",
    "      x = self.block8(x) + x\n",
    "      x = self.out(x)\n",
    "      return x\n",
    "class Green_loss2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,u_exact_r,u_exact_i,u_Green_r,u_Green_i):\n",
    "        return torch.mean(torch.pow((u_exact_r-u_Green_r),2)) +torch.mean(torch.pow((u_exact_i-u_Green_i),2))\n",
    "\n",
    "net1 = Net(100,2) \n",
    "Green_loss_func = Green_loss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = net1.to(device)\n",
    "sample_x = sample_x.to(device)\n",
    "G2_r = G2_r.to(device)\n",
    "G2_i = G2_i.to(device)\n",
    "A2_r = A2_r.to(device)\n",
    "A2_i = A2_i.to(device)\n",
    "sample_u_r = sample_u_r.to(device)\n",
    "sample_u_i = sample_u_i.to(device)\n",
    "sample_xk = sample_xk.to(device)\n",
    "KaparR2 = KaparR2.to(device)\n",
    "r0 = r0.to(device)\n",
    "n1 = n1.to(device)\n",
    "c = c.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss, epoch, computation time: 1.5490 0 3.1216\n",
      "loss, epoch, computation time: 1.0124 100 571.1881\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "\n",
    "# optimizer   优化器\n",
    "# Epoch       总训练次数\n",
    "# sample_h_r  样本点处密度函数值h(x)的实部\n",
    "# sample_h_i  样本点处密度函数值h(x)的虚部\n",
    "# u0_r        样本点处数值解实部\n",
    "# u0_i        样本点处数值解虚部\n",
    "optimizer = torch.optim.Adam(net1.parameters(net1),lr=0.0005)\n",
    "Epoch = 100\n",
    "loss_all = np.zeros(Epoch+1)\n",
    "loss = torch.Tensor([0]).to(device)\n",
    "time0 = time.time()\n",
    "for epoch in range(Epoch+1):\n",
    "    \n",
    "    if (epoch+1)%500==0:\n",
    "        k = (torch.cat((torch.rand(30)*1.5+2,torch.rand(40)*1.5+4.5),0)).to(device)\n",
    "        k1,k2 = (k*np.cos(theta0)).to(device) , (k*np.sin(theta0)).to(device)\n",
    "        for l in range(k_num):\n",
    "            sample_u_r[l,:] = (scp.hankel1(0,(k[l]*torch.sqrt((sample_x[:,0])**2+sample_x[:,1]**2)).cpu()).real).to(device)\n",
    "            sample_u_i[l,:] = (scp.hankel1(0,(k[l]*torch.sqrt((sample_x[:,0])**2+sample_x[:,1]**2)).cpu()).imag).to(device)\n",
    "\n",
    "            sample_xk[l*sample_num:(l+1)*sample_num,0:2] = sample_x\n",
    "            sample_xk[l*sample_num:(l+1)*sample_num,2] = k[l]\n",
    "\n",
    "        for l in range(k_num):\n",
    "            G2_r[l,:,:] = (scp.hankel1(1,(k[l]*r0).cpu()).imag).to(device)/4*n1/r0*k[l]\n",
    "            G2_i[l,:,:] = -(scp.hankel1(1,(k[l]*r0).cpu()).real).to(device)/4*n1/r0*k[l]\n",
    "        for l in range(k_num):\n",
    "            for i in range(sample_num):\n",
    "                A2_r[l,i,:],A2_i[l,i,:] = -c[i,:]*G2_r[l,i,:],-c[i,:]*G2_i[l,i,:]\n",
    "                A2_r[l,i,i],A2_i[l,i,i] = -1/2,0\n",
    "    \n",
    "\n",
    "    sample_h_r,sample_h_i = net1(sample_xk)[:,0],net1(sample_xk)[:,1]#这个方法甚至不需要内部点\n",
    "    loss = torch.Tensor([0]).to(device)\n",
    "    for l in range(k_num):\n",
    "        u0_r = (A2_r[l,:,:]@sample_h_r[l*sample_num:(l+1)*sample_num]-A2_i[l,:,:]@sample_h_i[l*sample_num:(l+1)*sample_num])\n",
    "        u0_i = (A2_r[l,:,:]@sample_h_i[l*sample_num:(l+1)*sample_num]+A2_i[l,:,:]@sample_h_r[l*sample_num:(l+1)*sample_num])\n",
    "        loss = loss + Green_loss_func(sample_u_r[l,:],sample_u_i[l,:],u0_r,u0_i)*k[l]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_all[epoch] = loss.cpu().detach().numpy() \n",
    "    if epoch%100==0:\n",
    "        print('loss, epoch, computation time:','%.4f'%loss.detach().numpy(),epoch,'%.4f'%(time.time()-time0))\n",
    "        time0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在问题所在区域内部测试精度\n",
    "\n",
    "# sample 内部采样点数\n",
    "# x_in   内部采样点坐标\n",
    "# u_in_r 内部点准确解实部 \n",
    "# u_in_i 内部点准确解虚部 \n",
    "# G_in_r 内部点对应积分矩阵实部\n",
    "# G_in_i 内部点对应积分矩阵虚部\n",
    "\n",
    "sample = 1500\n",
    "theta_in = torch.rand(sample,1)*2*np.pi\n",
    "r_in = torch.rand(sample,1)*(2-(9/20-1/9*torch.cos(5*theta_in)))+(9/20-1/9*torch.cos(5*theta_in))*1.01\n",
    "x0_in = torch.cos(theta_in)\n",
    "x1_in = torch.sin(theta_in)\n",
    "x_in = (torch.cat((x0_in,x1_in),1)*r_in).to(device)\n",
    "rprime = rprime.to(device)\n",
    "int_n = int_n.to(device)\n",
    "\n",
    "r0_in = (torch.zeros(sample,sample_num)).to(device)\n",
    "c_in = (torch.zeros(sample,sample_num)).to(device)\n",
    "for i in range(sample):\n",
    "    for j in range(sample_num):\n",
    "        d = sample_x[j,:]-x_in[i,:]\n",
    "        r0_in[i,j] = d.norm()\n",
    "        c_in[i,j] = (rprime[j,:].norm())/sample_num*2*np.pi*((d*int_n[j,:]).sum())/r0_in[i,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试精度\n",
    "# k_test 在[2,6]上等距取k_test个值作为k的值，分别测试其精度\n",
    "# l_all  每个k得到的相对L2误差\n",
    "# u_in_r 内部点准确解实部 \n",
    "# u_in_i 内部点准确解虚部 \n",
    "# G_in_r 内部点对应积分矩阵实部\n",
    "# G_in_i 内部点对应积分矩阵虚部\n",
    "k_test = 70\n",
    "kx = torch.zeros(k_test+1)\n",
    "l_all = torch.zeros(k_test+1)\n",
    "for i in range(k_test+1):\n",
    "    k = i/k_test*7+1\n",
    "\n",
    "    u_in_r = (scp.hankel1(0,(k*torch.sqrt((x_in[:,0])**2+x_in[:,1]**2)).cpu()).real).to(device) \n",
    "    u_in_i = (scp.hankel1(0,(k*torch.sqrt((x_in[:,0])**2+x_in[:,1]**2)).cpu()).imag).to(device) \n",
    "\n",
    "    G2_in_r = (scp.hankel1(1,(k*r0_in).cpu()).imag).to(device)/4*c_in*k\n",
    "    G2_in_i = -(scp.hankel1(1,(k*r0_in).cpu()).real).to(device)/4*c_in*k\n",
    "    x_sample_in = (torch.zeros(sample_num,3)).to(device)\n",
    "    x_sample_in[:,0:2] = sample_x\n",
    "    x_sample_in[:,2] = k\n",
    "    sample_h_r,sample_h_i = net1(x_sample_in)[:,0],net1(x_sample_in)[:,1]\n",
    "\n",
    "    u_green_r = -(G2_in_r@sample_h_r-G2_in_i@sample_h_i)\n",
    "    u_green_i = -(G2_in_r@sample_h_i+G2_in_i@sample_h_r)\n",
    "    kx[i] = k\n",
    "    l_all[i] = (((u_green_r-u_in_r)**2+(u_green_i-u_in_i)**2).sum()/((u_in_r)**2+(u_in_i)**2).sum()).sqrt()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
