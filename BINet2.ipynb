{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 此程度对应了文章中的第三个实验，用于求解光滑区域上的Helmholtz方程"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import scipy.special as scp\r\n",
    "from torch.autograd import Variable as v\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 设置求解区域，样本点和求出精确解\r\n",
    "\r\n",
    "# k          波数\r\n",
    "# theta0     准确解平面波的方向\r\n",
    "# sample_num 样本点数\r\n",
    "# sample_x   边界样本点坐标\r\n",
    "# sample_u_r 准确解实部\r\n",
    "# sample_u_i 准确解虚部\r\n",
    "# rprime     边界参数化方程在样本点处切向量\r\n",
    "# int_n      样本点处的外法向量\r\n",
    "k , theta0 = 4 , np.pi/7\r\n",
    "k1,k2 = k*np.cos(theta0) , k*np.sin(theta0) \r\n",
    "sample_num = 800 \r\n",
    "\r\n",
    "theta = torch.linspace(2*np.pi/sample_num,2*np.pi,sample_num).reshape(-1,1)\r\n",
    "r = 9/20-1/9*torch.cos(5*theta)\r\n",
    "x0,x1 = torch.cos(theta),torch.sin(theta)\r\n",
    "sample_x = torch.cat((x0,x1),1)*r\r\n",
    "\r\n",
    "sample_u_r = torch.cos(k1*sample_x[:,0]+k2*sample_x[:,1]); \r\n",
    "sample_u_i = torch.sin(k1*sample_x[:,0]+k2*sample_x[:,1]);\r\n",
    "\r\n",
    "rprime = torch.cat((-x1*r+5/9*torch.sin(5*theta)*x0,x0*r+5/9*torch.sin(5*theta)*x1),1)\r\n",
    "int_n = rprime@torch.Tensor([[0,-1],[1,0]])\r\n",
    "int_n = int_n/((int_n*int_n).sum(axis=1).reshape(-1,1).sqrt())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 设置积分矩阵\r\n",
    "\r\n",
    "# G1_r    基本解的实部\r\n",
    "# G1_i    基本解的虚部\r\n",
    "# A1_r    积分矩阵的实部\r\n",
    "# A1_i    积分矩阵的虚部\r\n",
    "# KaparR2 Kapar奇异积分的权重\r\n",
    "time11 = time.time()\r\n",
    "G1_r = torch.zeros(sample_num,sample_num)\r\n",
    "G1_i = torch.zeros(sample_num,sample_num)\r\n",
    "for i in range(sample_num):\r\n",
    "    for j in range(sample_num):\r\n",
    "        d = sample_x[j,:]-sample_x[i,:]\r\n",
    "        r0 = d.norm()\r\n",
    "        G1_r[i,j] = -scp.hankel1(0,k*r0).imag/4\r\n",
    "        G1_i[i,j] = scp.hankel1(0,k*r0).real/4\r\n",
    "KaparR2 = torch.zeros(sample_num,1)\r\n",
    "KaparR2[0],KaparR2[1] = 1.825748064736159,-1.325748064736159\r\n",
    "A1_r = torch.zeros(sample_num,sample_num)\r\n",
    "A1_i = torch.zeros(sample_num,sample_num)\r\n",
    "for i in range(sample_num):\r\n",
    "    for j in range(sample_num):\r\n",
    "        if i==j:\r\n",
    "            A1_r[i,j],A1_i[i,j] = 0,0\r\n",
    "        else:\r\n",
    "            c = (1+KaparR2[abs(((i-j)+round(sample_num/2))%sample_num-round(sample_num/2)-1)])*((rprime[j,:]).norm())/sample_num*2*np.pi\r\n",
    "            A1_r[i,j],A1_i[i,j] = -c*G1_r[i,j],-c*G1_i[i,j]\r\n",
    "time12 = time.time()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 构造网络和损失函数\r\n",
    "\r\n",
    "# 全连接网络\r\n",
    "# m 神经元个数\r\n",
    "# Helmholtz 方程中输出是2维，分别代表实部和虚部\r\n",
    "class Net(nn.Module):\r\n",
    "  def __init__(self,m):\r\n",
    "    super(Net, self).__init__()\r\n",
    "    self.net=nn.Sequential(\r\n",
    "      nn.Linear(in_features=2,out_features=m),nn.Tanh(),\r\n",
    "      nn.Linear(m,m),nn.Tanh(),\r\n",
    "      nn.Linear(m,m),nn.Tanh(),\r\n",
    "      nn.Linear(m,m),nn.Tanh(),\r\n",
    "      nn.Linear(m,m),nn.Tanh(),\r\n",
    "      nn.Linear(m,2)\r\n",
    "    )\r\n",
    "  def forward(self, input:torch.FloatTensor):\r\n",
    "    return self.net(input)\r\n",
    "\r\n",
    "# MSE loss    \r\n",
    "class Green_loss(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "    def forward(self,u_exact_r,u_exact_i,u_Green_r,u_Green_i):\r\n",
    "        return torch.mean(torch.pow((u_exact_r-u_Green_r),2)) +torch.mean(torch.pow((u_exact_i-u_Green_i),2)) \r\n",
    "\r\n",
    "net1 = Net(40) #用格林函数形式作为损失函数\r\n",
    "Green_loss_func = Green_loss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#训练过程\r\n",
    "\r\n",
    "# optimizer   优化器\r\n",
    "# Epoch       总训练次数\r\n",
    "# sample_h_r  样本点处密度函数值h(x)的实部\r\n",
    "# sample_h_i  样本点处密度函数值h(x)的虚部\r\n",
    "# u0_r        样本点处数值解实部\r\n",
    "# u0_i        样本点处数值解虚部\r\n",
    "optimizer = torch.optim.Adam(net1.parameters(net1),lr=0.001)\r\n",
    "Epoch = 1000\r\n",
    "time0 = time.time()\r\n",
    "for epoch in range(Epoch+1):\r\n",
    "    sample_h_r,sample_h_i = net1(sample_x)[:,0],net1(sample_x)[:,1]#这个方法甚至不需要内部点\r\n",
    "    \r\n",
    "    u0_r = (A1_r@sample_h_r-A1_i@sample_h_i)\r\n",
    "    u0_i = (A1_r@sample_h_i+A1_i@sample_h_r)\r\n",
    "\r\n",
    "    loss = Green_loss_func(sample_u_r,sample_u_i,u0_r,u0_i)\r\n",
    "    optimizer.zero_grad()\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if epoch%1000==0:\r\n",
    "        print('loss, epoch, computation time:','%.4f'%loss.detach().numpy(),epoch,'%.4f'%(time.time()-time0))\r\n",
    "        time0 = time.time()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss, epoch, computation time: 0.0162 0 0.0399\n",
      "loss, epoch, computation time: 0.0015 1000 21.8296\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# 在区域内部测试精度\r\n",
    "\r\n",
    "# sample 内部采样点数\r\n",
    "# x_in   内部采样点坐标\r\n",
    "# u_in_r 内部点准确解实部 \r\n",
    "# u_in_i 内部点准确解虚部 \r\n",
    "# G_in_r 内部点对应积分矩阵实部\r\n",
    "# G_in_i 内部点对应积分矩阵虚部\r\n",
    "sample = 1000\r\n",
    "theta_in = torch.rand(sample,1)*2*np.pi\r\n",
    "r_in = torch.rand(sample,1)*(9/20-1/9*torch.cos(5*theta_in))*0.99\r\n",
    "x0_in = torch.cos(theta_in)\r\n",
    "x1_in = torch.sin(theta_in)\r\n",
    "x_in = torch.cat((x0_in,x1_in),1)*r_in\r\n",
    "\r\n",
    "u_in_r = torch.cos(k1*x_in[:,0]+k2*x_in[:,1]); \r\n",
    "u_in_i = torch.sin(k1*x_in[:,0]+k2*x_in[:,1]);\r\n",
    "\r\n",
    "G1_in_r = torch.zeros(sample,sample_num)\r\n",
    "G1_in_i = torch.zeros(sample,sample_num)\r\n",
    "for i in range(sample):\r\n",
    "    for j in range(sample_num):\r\n",
    "        d = sample_x[j,:]-x_in[i,:]\r\n",
    "        r0 = d.norm()\r\n",
    "        c_in = (rprime[j,:].norm())/sample_num*2*np.pi\r\n",
    "        G1_in_r[i,j] = -scp.hankel1(0,k*r0).imag/4*c_in\r\n",
    "        G1_in_i[i,j] = scp.hankel1(0,k*r0).real/4*c_in"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# BINet求得的数值解实部和虚部\r\n",
    "u_green_r = -(G1_in_r@sample_h_r-G1_in_i@sample_h_i)\r\n",
    "u_green_i = -(G1_in_r@sample_h_i+G1_in_i@sample_h_r)\r\n",
    "\r\n",
    "# 打印相对L2误差\r\n",
    "print('Relaive L2 error:','%.4f'%(((((u_green_r-u_in_r)**2).sum()+((u_green_r-u_in_r)**2).sum())/((u_in_r**2).sum()+(u_in_r**2).sum())).sqrt()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relaive L2 error: 0.0110\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "7e807f9ddb0496b7851a27b2566c8810a6974b896f5c34231241c2796bf1297c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}